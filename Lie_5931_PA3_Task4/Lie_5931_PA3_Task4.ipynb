{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lie_5931_PA3_Task4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobby-lie/Recurrent-Neural-Network-from-Scratch/blob/master/Lie_5931_PA3_Task4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC6lGVzR61ul",
        "colab_type": "code",
        "outputId": "1168773f-f79e-4c9a-b001-870e87d069c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTSk79mH5kYn",
        "colab_type": "code",
        "outputId": "8c81eeee-ba26-4aaf-a89b-df6d125e9dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import csv\n",
        "import itertools\n",
        "import operator\n",
        "import sys\n",
        "from datetime import datetime\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/5931_PA3\n",
        "%ls\n",
        "\n",
        "!pip3 install nltk"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/5931_PA3\n",
            "Lie_5931_PA3_Task1.ipynb  Lie_5931_PA3_Task4.ipynb\n",
            "Lie_5931_PA3_Task3.ipynb  SciFi_Three.txt\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpqJ0Wsa7DQe",
        "colab_type": "code",
        "outputId": "c963d413-17ea-48b5-c8e2-afa4c4db4ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "import nltk\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download()"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n",
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Package punkt is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YkbA-_i7aWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_loss_epoch_plt(losses):\n",
        "  ''' generates loss vs epoch plot based off of list of losses generted from training'''\n",
        "  x_plt = []  # holds x values\n",
        "  y_plt = []  # holds y values\n",
        "\n",
        "  epoch_ct = 0  # need epoch_ct to keep track of which epoch the loss belongs to\n",
        "  # for each loss add the epoch and appropriate loss from tuple to x and y\n",
        "  for loss in losses:\n",
        "    x_plt.append(epoch_ct)\n",
        "    y_plt.append(loss[1])\n",
        "    epoch_ct += 1\n",
        "\n",
        "  plt.plot(x_plt, y_plt)  # plot from x and y lists\n",
        "  plt.title('Loss vs. Epoch') # title \n",
        "  plt.ylabel('Loss') # y axis title\n",
        "  plt.xlabel('Epoch') # x axis title\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Aq3B1NOGj_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open('SciFi_Three.txt', 'r').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loFj3pCTG71X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg_LqfWuHN-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 8000\n",
        "unknown_token = \"UNKNOWN\"\n",
        "sentence_start_token = \"SENTENCE_START\"\n",
        "sentence_end_token = \"SENTENCE_END\"\n",
        "num_ascii_char = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx8-yOxBNzPo",
        "colab_type": "text"
      },
      "source": [
        "### From file specified, from each paragraph, tokenize into sentences and add sentence_start_token and sentence_end_token into sentences. Get rid of the newline character and replace with a space and append to the sentence_list. Finally, report how many sentences there are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qoa_5l8G_kX",
        "colab_type": "code",
        "outputId": "6afe615e-f85d-4f04-8c73-a38065e2874e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Reading .txt file...\")\n",
        "\n",
        "sentences = []\n",
        "sentence_list = []\n",
        "filename = \"SciFi_Three.txt\"\n",
        "with open(filename, \"r\") as f:\n",
        "    \n",
        "    # Split all paragraphs by two newline characters\n",
        "    all_content = f.read()\n",
        "    paragraphs = all_content.split(\"\\n\\n\")\n",
        "    \n",
        "    # For each paragraph, tokenize sentences and then place in sentence_list\n",
        "    for paragraph in paragraphs:\n",
        "\n",
        "        sentences = nltk.sent_tokenize(paragraph.lower())\n",
        "        \n",
        "        sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.replace(\"\\n\", \" \")\n",
        "            sentence_list.append(sentence)\n",
        "            \n",
        "print(\"Parsed %d sentences.\" % (len(sentence_list)))  # report how many sentences"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading .txt file...\n",
            "Parsed 25324 sentences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scKOqig3HRgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "# for each sentence in sentence_list\n",
        "# get all words from each sentence and \n",
        "# in our word list only include the unique words \n",
        "for sent in sentence_list:\n",
        "  temp = nltk.word_tokenize(sent) # tokenize each setnence\n",
        "  for x in (set(temp)):\n",
        "    words.append(x) # append only unique words\n",
        "words = set(words) # further ensure only unique words  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMHBsPvmIX4p",
        "colab_type": "code",
        "outputId": "629888d3-68e6-4580-ef92-0a376df4b4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_size, X_size = len(data), len(words) # get data length and word length\n",
        "print(\"data has %d words, %d unique\" % (data_size, X_size))\n",
        "word_to_idx = {ch:i for i,ch in enumerate(words)} # create word to index dict\n",
        "idx_to_word = {i:ch for i,ch in enumerate(words)} # create index to word dict\n",
        "data = nltk.word_tokenize(data) # data is now a list of its words"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 2442629 words, 20063 unique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SLXESv39Vie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants and hyper-params\n",
        "H_size = 100 # Size of the hidden layer\n",
        "T_steps = 12 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning rate\n",
        "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
        "z_size = H_size + X_size # Size of concatenate(H, X) vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pVCRyb4Iren",
        "colab_type": "text"
      },
      "source": [
        "### We define the sigmoid and tanh functions here as well as their derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUUafccq95l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def dsigmoid(y):\n",
        "    return y * (1 - y)\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def dtanh(y):\n",
        "    return 1 - y * y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2_VQ4B499PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
        "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
        "# Biases are initialized to zeros.\n",
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "        self.name = name\n",
        "        self.v = value #parameter value\n",
        "        self.d = np.zeros_like(value) #derivative\n",
        "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
        "        \n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', \n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd)\n",
        "        self.b_C = Param('b_C',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v',\n",
        "                         np.random.randn(X_size, H_size) * weight_sd)\n",
        "        self.b_v = Param('b_v',\n",
        "                         np.zeros((X_size, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiZS9IeX-C5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (H_size, 1)\n",
        "    assert C_prev.shape == (H_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJxqWPhz-VmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + H_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (H_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:H_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wotRsmALjan",
        "colab_type": "text"
      },
      "source": [
        "### Forward Backward Pass\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKGaaEPH-YIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear gradients before each backward pass\n",
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFn65YXD-aG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clip gradients to mitigate exploding gradients\n",
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKfRGrix-bzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == T_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqHvpAAALcJZ",
        "colab_type": "text"
      },
      "source": [
        "# Generate next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5l-yznz-eM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_next_char(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36AuDT_DLXcG",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVDgdVVF-gYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update the graph and display a sample output\n",
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ' '.join(idx_to_word[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.title(\"Loss vs Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF4vyA-8-in0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc54U-fV-m8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPtPxvtBLSsR",
        "colab_type": "text"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFJqCWto-pG2",
        "colab_type": "code",
        "outputId": "41e80e2c-7d2b-406c-a9ab-57f806b99a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "cellView": "both"
      },
      "source": [
        "count = 0\n",
        "iter_loss= []\n",
        "iters = 41\n",
        "\n",
        "while count < iters:\n",
        "    #try:\n",
        "        #with DelayedKeyboardInterrupt():\n",
        "  # Reset\n",
        "  if pointer + T_steps >= len(data) or iteration == 0:\n",
        "    g_h_prev = np.zeros((H_size, 1))\n",
        "    g_C_prev = np.zeros((H_size, 1))\n",
        "    pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([word_to_idx[ch.lower()] \n",
        "              for ch in data[pointer: pointer + T_steps]])\n",
        "  targets = ([word_to_idx[ch.lower()] \n",
        "              for ch in data[pointer + 1: pointer + T_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 40 == 0:\n",
        "    update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  print((iteration,loss))\n",
        "\n",
        "  pointer += T_steps\n",
        "  iteration += 1\n",
        "  count += 1"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deXiTddb3v9nTLN2ytKUUKNCyWBYZ\nHIVBEQHBhUcfHTeEGedxm1FGHwdHcRmXy5nHdWZUZN5HnRkXkNGRGZf3HR1wVxBxYS0CbaGF7kna\nJs3abPf7R3qnaZqkd5I7W3M+1+V1QZrmPr0r35yc3znfI2AYhgFBEASRVwgzHQBBEASRfkj8CYIg\n8hASf4IgiDyExJ8gCCIPIfEnCILIQ0j8CYIg8hBxpgMgCK5MmzYNn332GcrLyzMdCiemTZuGCRMm\nQCQSDXv8iSeewOzZs3m91nnnnYcnnngC8+fP5/V1ibELiT9BpJDNmzfnzJsVkV9Q2YfIeQYGBvDA\nAw9gxYoVuOCCC/DYY4/B5/MBALZs2YILLrgAK1euxI9//GM0NjbGfJylqakJP/zhD+H1eoOP3XLL\nLfjb3/6GhoYGXHXVVbjoootw/vnnY8uWLXHHvGfPHqxatQqPPfYYVqxYgfPOOw/79+8f9eepr6/H\nZZddhhUrVmDNmjVobW0NvmZ9fT2uvPJKLFq0CI8++mjcMRF5BkMQOUJtbS3T2dk54vHnn3+eufHG\nGxmPx8M4nU7m8ssvZ95++23GarUy8+fPZ6xWK8MwDPPee+8xL7zwQtTHw7nggguY3bt3MwzDMA6H\ngzn99NOZnp4e5pe//CXzz3/+k2EYhunp6WF+8YtfMAMDA5zjZRiG+eqrr5gZM2Yw//rXvxiGYZi/\n//3vzCWXXBLz52EYhlm+fDnz6aefMgzDMC+99BJz4403MgzDMEuWLGHWr1/PeL1epquriznttNOY\njo4OjneWyEeo7EPkPJ9++in+67/+C2KxGGKxGKtWrcKuXbtw4YUXQiAQYNu2bbj44otxwQUXAAA8\nHk/Ex8NZsWIFPv74Y5x11ln44osvMHv2bJSWlkKj0WD79u2ora3FzJkz8ac//SlqbGvXrh1W8y8t\nLcXWrVsBAAqFInjt888/H/fffz+cTmfUn2f27Nno6+vD4sWLAQBr1qzBNddcE3ztVatWQSQSoays\nDBqNBl1dXaioqEju5hJjFir7EDlPb28vioqKgn8vKipCT08PJBIJXn75ZezduxcrVqzA6tWrcezY\nsaiPh8OKPwB8+OGHuPDCCwEAd955J2pra/Hf//3fWLx4MV577bWosW3evBn//ve/g/+xwg8AhYWF\nEAgEwT8DQH9/f9Sfp6+vD2q1Ovi4WCyGTCYL/l2pVAb/LBKJgqUigogEiT+R82i1WpjN5uDfzWYz\ntFotAGDmzJl49tlnsXv3bixatAgPPvhgzMdDmT59OkQiEY4ePYqdO3di+fLlAAIi+6tf/QoffPAB\nnnvuOTz77LNobm6OO+7QmC0WCwCguLg46s9TUlICs9kMv98PIPAJpq2tLe7rEgRA4k+MAc4991xs\n27YNPp8PDocD77zzDhYvXoxjx47htttug9vthlQqRV1dHQQCQdTHI7FixQps3LgRM2bMQElJCQDg\n5z//efCAuLa2FiqVKur3x8LlcuHDDz8EAGzfvh11dXWQyWRRf55JkyahvLwcO3bsAABs27YNDzzw\nQCK3jCCo1ZPILcJr6L/97W+xdu1atLa24qKLLoJAIMDKlSuDtfTx48fj4osvhkQigVKpxAMPPIDa\n2tqIj0dixYoVuOyyy/Db3/42+NiaNWuwfv16eDweAMDq1asxadIkTvGy319TU4PKykp89913ePLJ\nJ+HxePD0008HvyfSzyMQCPDMM8/g17/+Nf7whz9Ap9NRVw+RMAKGIT9/gkg3e/bswf33348PPvgg\n06EQeQqVfQiCIPIQEn+CIIg8hMo+BEEQeQhl/gRBEHlITnT7uFwu1NfXQ6fTjeicIAiCIEbi8/lg\nNBpRV1cHuVw+4us5If719fW49tprMx0GQRBEzvHaa69FtPrOCfHX6XQAAj8E2eMSBEGMTldXF669\n9tqgfoaTE+LPlnrKy8sxfvz4DEdDEASRO0QrldOBL0EQRB5C4k8QBJGHkPgTBEHkIST+BEEQeQiJ\nP0EQRB5C4k8QBJGHkPiPUbZ914ZLNu3KdBgEQWQpJP5jlD0nenCg1Qz7gDfToRAEkYWQ+I9Ruvpd\nAACTbSDDkRAEkY3kvfh3WVzw+8eeq3WnJSD+RiuJP0EQI8lr8X/vUCfOevQjfHikO9Oh8ArDMOg0\nOwFQ5k8QRGTyVvwbu6349ZsHAABHOq0ZjoZfrANe2N0+AIDR5s5wNARBZCM5YezGN1aXBzdv/g4F\nUhFkEhGaTbZMh8QrnWZX8M8mKvsQBBGBlGb+DQ0NWLZsGbZs2QIA6OzsxHXXXYc1a9bguuuug9Fo\nBAC8++67uPzyy3HFFVfgzTffTGVIYBgGd755ACd7HXhu9TzMqFCjuceR0mumm06LM/hnI5V9CIKI\nQMrE3+Fw4JFHHsGCBQuCjz399NO48sorsWXLFixfvhwvvfQSHA4HNm3ahJdffhmbN2/GK6+8ArPZ\nnKqw8H8+O47th7txzwXTcdZkDSZplGg22jCWVhmzh71quZgyf4IgIpIy8ZdKpXjxxReh1+uDjz34\n4INYsWIFAKCkpARmsxkHDhzArFmzoFarIZfLMW/ePOzduzclMX3RaMRT249h1ZxxuH5RNQCgWqtE\nv8uLPocnJdfMBJ0WFwQCYEZFIR34EgQRkZSJv1gsHrE3UqFQQCQSwefzYevWrVi1ahVMJhNKS0uD\nzyktLQ2Wg/ikrc+B2/62DzV6NR6/fBYEAgGAgPgDQLPJzvs1M0WXxQmdSoaKIjlMdOBLEEQE0t7t\n4/P5cNddd+Gss84aVhJiSUX5xeXx4Rdb9sLrY/C/a38AhXTonHvSoPi3jCHx77S4UFFcAK1KRn3+\nBEFEJO3if88992DixIlYt24dAECv18NkMgW/bjAYhpWKkoVhGPzm7Xocarfgj1fNDWb6LFUlCggF\nYyvz77S4UFEoh04tg9PjI4sHgiBGkFbxf/fddyGRSHDbbbcFH5szZw4OHTqE/v5+2O127N27N+Km\n+UTZ+vUpvPldG247byqWzSwb8XWpWIiqUgWae8aG+LMDXuVFcmhVMgA06EUQxEhS1udfX1+Pxx9/\nHO3t7RCLxdi+fTt6enogk8mwdu1aAMCUKVPw0EMPYf369bj++ushEAhw6623Qq1W8xbHq1+exLnT\ndLh9WW3U50zSKMdM2Ycd8BpXLIdWJQUQEP+JGuUo30kQRD6RMvGvq6vD5s2bOT135cqVWLlyZUri\n+NtNZ6GoQAKRUBD1OdVaJb5p6QXDMMGD4Fyla7DNs7yoIJj5U92fIIhwxry9Q6lSGlP4gYD4O9y+\nMSGSHYOePuOK5NCrB8WfOn4IgghjzIs/FyaNoXbPocxfjlKlFAIBWTwQBDESEn8A1YP18JYxcOjb\nMTjgVVYoh1gkRIlCSge+BEGMgMQfQGVJASQiAU6Micw/MOAlEQV+tVqVdEyUswiC4BcSfwAioQAT\nShVjouOn0+JCRdHQZLVOLaPMnyCIEZD4D1KtVaLFlPvungHxLwj+XauSkcUDQRAjIPEfpFqrREuP\nPedXOnZZXCgPyfwD4k+ZP0EQwyHxH2SSVokBrx+d/a7Rn5yl9Ls8sA14Ma54uPg73GTxQBDEcEj8\nBwl2/ORw3T90wItFpyaLB4IgRkLiP0i1LiD+udzxww54VQwr+wxZPBAEQbCQ+A9SppZDLhGOicy/\nIqzmDwBGKx36EgQxBIn/IEKhIOcN3jpDBrxYdEGLB8r8CYIYgsQ/hGqtMqctHjrDBrwAkMUDQRAR\nIfEPYZJWiVO9Dnh9/kyHkhDhA14AICGLB4IgIkDiH0K1Rgmvn0H74MFprhE+4MWiVZH4EwQxHBL/\nENiOn1wt/YQPeLHQLl+CIMIh8Q9hkiZ3xZ8d8Aov+wCsvw91+xAEMQSJfwhalRQqmZi3jh+/nwHD\npMcuItjmWRyp7EMWDwRBDIfEPwSBQBDo+OlJ3uCNYRjc8Oq3uP31/TxENjqdEXr8WcjigSCIcEj8\nw5ikVaLZZEv6dXY2mfDxUQPq2y08RDU6nRGme1loypcgiHBI/MOo1ijQ3ueE25t4uyfDMHhy+zEA\ngYw8HaWfSANeLOTvQxBEOCT+YVTrlPAzwKnexEs/2w934WCbBaeNK4TT40O/M/XllkgDXixk8UAQ\nRDgk/mEk2/Hj8zN4akcDpupVuOmcyQCArjTYREca8GLJp8zf5fHhkud24uvm3kyHQhBZDYl/GNXa\n5Kyd39rXjiaDDeuX16JysPOm05L6obHOKD3+QMDiAUBe9Pp3Wlw40GbBziZTpkMhiKyGxD+MYoUU\nJQoJmnviF/8Brw9//KABsyqLsLKuPCjG3WnI/LuiTPcCAYuHUmV+TPmaHYHSVmsSZTuCyAdI/CMw\nSZuYu+frX7ei3ezEr1dMg0AggF4th0Aw1IaZKqwxBrxY8sXiwezwACDxJ4jRIPGPQLUmfndPh9uL\njR834czqUpxdowUASMVCaJSy4ABWquiMMeDFki+L3PsGM/9kDuwJIh8g8Y9AtVaJTosLTreP8/e8\ntKsFJtsA7loZyPpZKorkKT/wjTXgxZIv/j5s5m+wDsDl4f77I4h8g8Q/ApMGD31P9nLL/i0OD57/\n7DiWTtfjBxNLh32trFCe+sx/cMCrPEKPP0vA3ycfxH/o001bX266sxJEOiDxjwDb8dNs5Cb+z39+\nHP0uL+5cMW3E19KV+Ucb8GJhLR4c7rFt8dA3mPkDVPcniFiQ+EeAzfy5dPwYrC68tKsF/zFnHGZU\nFI74enmRHGaHJ6UliC6LC1qVDFJx9F9n0OJhjA96mZ0eqGViAEBrH4k/QUSDxD8CKpkYOrWMU8fP\npo+b4Pb5ccfy2ohfZ0sxqSz9dFicGBej3g8A2uAu39S3nWYSs8ONKXoVZGIhTvFg0EcQYxUS/yhw\n6fhp7XVg69encOX8qmCpKBz2EDaV7Z7RlriEossTi4c+hxulSimqShWU+RNEDFIq/g0NDVi2bBm2\nbNkSfOzVV1/FaaedBrt9SFjfffddXH755bjiiivw5ptvpjIkzkzSKtBsii4eLo8Pd755AEKBALct\nnRr1eWWDotzVn7rDx2jrG0PJF4sHs8OD4gIJJpQq0NpLB74EEQ1xql7Y4XDgkUcewYIFC4KPvf32\n2+jp6YFerx/2vE2bNmHbtm2QSCT48Y9/jOXLl6O4uDhVoXGiWquCydYGq8sDtVwy7Gs+P4PbX9+H\nPc29eObquTGFd6jskxrR5TLgBQxZPOSF+CukUMvF+Ka5FwzDDGu9JQgiQMoyf6lUihdffHGY0C9b\ntgx33HHHsH+MBw4cwKxZs6BWqyGXyzFv3jzs3bs3VWFxplqrAAC0hGX/DMPg/rcPYfvhbjy4aiYu\nmVsZ83WUMjEK5WJ0pcjfhy0njVb2kYiEKFFIxnSvv9vrh23AixKFBFWlClgHvLA4PaN/I0HkISkT\nf7FYDLl8uCCpVKoRzzOZTCgtHeqNLy0thdFoTFVYnInW8fP7HQ3429etWLdkKn72o2pOr1WewnZP\nVvzHxZjuZRnrvf6s0BcPij9Ak74EEY2sO/BN187b0WCtnUM7fl7a1YznPmnCNT+swvrzI3f3RKK8\nqCBl3T7sJ4pYA14sY93igR3wKlZIUVUSEH+q+xNEZDIu/nq9HibTkP2uwWAYVirKFHKJCOOK5EHx\nf2d/Ox7+v99jxWlleOSSurjqyOWFspR1+3SYRx/wYhnri9zZAa9A5h/4JESZP0FEJuPiP2fOHBw6\ndAj9/f2w2+3Yu3cv5s+fn+mwAARKPydMdnx6zID1fz+AM6tL8czVp0McYVtWLMqLCmC0DcDjS3w1\nZDS4DHixjHV/HzbzL1FIoZZLUKKQULsnQUQhZd0+9fX1ePzxx9He3g6xWIzt27dj4cKF+PLLL2E0\nGnHjjTdi7ty5uOuuu7B+/Xpcf/31EAgEuPXWW6FWq1MVVlxUa5X45952/GLLXtSUqfHiT+dDLhHF\n/TrlhXIwTGCZCpfafDx0WJyjdvqw6NRDFg8Kaexf/dv72jFVr0JdZREfYaYFc0jmD2Cw3XPsiP87\n+9vx+x0N+Gj94ojrOgkiHlIm/nV1ddi8efOIx3/xi1+MeGzlypVYuXJlqkJJmGqtEk6PDxNKFXjl\nv85AYVjLJ1cqgr3+Lt7Fv8viwmRd5AGzcEItHiZoov/qbQNe3PnmAZw1WYMtN5zJS5wsDMPg6+Ze\n9Lu8WD6zjNfX7gup+QPA+FIFDrdbeL1GJvnn3nac6nXAYB0IbokjiESh9CEGZ9fosHCKBpuv/yH0\nam7ZdSTYNsxUHPrG2uAVzpDFQ+zSz9fNPfD6Gew+0TPMJTMZ7ANevLbnJC545gtc9cJXuHnzt7yX\nwcxODyQiAZTSwKezqhIF2s1O+PzZ0USQDE63D7tP9ADIj3WcROoh8Y/BtHI1tt54FiZquGXW0UiV\nv4/V5YGVw4AXy5DFQ2zx2NkYEBmfn8GHRwxJxXjcaMND7x7GWf/zEe57qx5CgQDLZpTBzwD9PPfg\nmx1uFCukwcP4CaUKeHxMyl1V08HuEya4vYE3SxJ/gg9SVvYhhihWSCATC3kXoS6OA14sXC0edjWZ\n8KOpGjQb7fh3fSd+/IPxccf20ZFuvPxlC75oNEEiEuCCugr8dOFEzJtQgnf2d+DDI90wOz3QDL4h\n8UGfPWDtwMJ2/LT2OnK+TPLJUSOEAsDPBJxkCSJZSPzTgEAgQHmRnPd2z444BrwAbhYPBqsLx7qt\nuPT06agtU+O1PadgG/BCJeP+v8q/Dnbi1q17UV4ox/rltbjqh1XDymZFgweyZgfPmb/TjZLBej8Q\nyPyBgPifNVnD67XSCcMw+OSYAefU6vBZg5Eyf4IXqOyTJsoL5ejmWfzjGfAChiweYon/7uOBks+P\npmqw8rRyuL1+fHosvtLPlq9Ooqq0AF/cvQS/XFoz4ryEzc75L/t4gp0+QOBNUSjI/aUux412tPU5\nsXxmGUoVUhhI/AkeIPFPExVFcnTy7OwZz4AXy2i9/jsbTSgqkOC0cUWYP6kUWpUU79d3cX79FpMd\nu0/04Kr5VVHbEYsGxd/s5HfauM/hHib+EpEQFUUFaM3xdY7sm++50/TQqcf2rAaRPkj800RZkRzd\nlgFe7SviGfBiCfj7RBZdhmGwq8mEhVM0EAkFEAkFWD6zHJ8cNXDeRPbGt60QCoAr5ldFfQ7bimnh\nu+zj8Awr+wCBun+uT/l+esyI2jIVKosLoFPLKPMneIHEP01UFMrh9vnRa+cv2+3sd3Hu9GGJZfHQ\n0uNAh8WFhVO1wcdW1pXD4fbhi0ZTxO8JxePzY9t3bThvuj7mp5FCeeD8wMxj2cfp9mHA6w++sbBU\nleT2oJd9wIs9zT1YMi1geaJTy2Ai8Sd4gMQ/TZSnYKNXp5n7dC+LVhVdPHY2BQR+UYj4L5isQaFc\njH9zKP18fNQAo3UAV58xIebzxCIh1DIxr3bLQwNewwfxJpQqYLAOpHSHcirZ1WSCx8dg8TQdAATL\nPtligEjkLiT+aaJ8cBCrm8d2z3gGvFi0ainsgxYP4XzZZEJlcQEmaRTBx6RiIZbNKMOHR7pHHcp6\n45tWlBXKcO6gUMWisEDCa9mH7RwqCRN/1tq5LUc9fj45ZoRKJsb8iQHbc7068AmS9hQQyULinyb4\n3uXLDnhx7fFnYQe9TGG7fH1+Bl8e78HCKZoRjqUr68phcXrw1eCEaSQ6LU58esyAK35Qxcn4rlgh\n4bXsYw6zdmCpKs1da2eGYfDZMQMWTdUGz3XYWQ069CWShcQ/TWhVMoiEAt4yf3bAK+6yTxSLh8Md\nFlicHiyq0Y74nnNqdSiQiGKWft78tg1+BrgyxkFvKMUKCa/Zq9k53NSNJZetnRu6beiwuLBk+tAn\nKf3g748OfYlkIfFPEyKhAHo1f77+HUHxj6/sE8z8w8R/V1Mgq184ZaT4yyUiLJmuw/bD3RF9cvx+\nBm9804pFU7WYEFIyikVRgYQ33yBgqOYf3u2jU8kglwhz8tD3k8EWz8W1Q/stKPMn+ILEP42UFcp5\ny/wbuqwAgElabmLLoo3i77OryYRpZeqguISzsq4CJtsA9p7qG/G1nU0mtJuduOoMblk/ABQVSGFx\njjx3SBS25l9UMDzzFwgEqCpR5GTm/+kxA2ZUFA4r7Q1l/mTxQCQHiX8aqeDR4mHvqT6MLymI221U\noxpp8eDy+PBNSy9+NHVk1s+yZJoOUpEwYunnjW9aUaKQ4PzTuFs0FxVIYHG6eetaMTvcKJCIIu5b\nqCpV5NygV7/Lg29b+rAk7PBcJRNDLhFS5k8kDYl/GikvkvPi7MkwDPae6sO8CSVxf28ki4e9J/sw\n4PVjUU10/xu1XIJFNVr8u75rmGD32Aaw4/suXDZvPGRi7otuihUSeHwMHG5+WjD7HJ4RnT4sE0oV\naOt15FR75K5GE7x+BudOG77SVCAQ0JQvwQsk/mmkvFAO24AXVldyB50dFhe6+wcwb0JxQt8f6PUf\nqrfvbDJBLBTgh9Wxzc9W1pWj3exEfXt/8LF/7m2Hx8fg6jhKPsCQvw9fh75mhxtFYfV+lvElBbAO\neHk3kkslnxwzQC0XR/wd69VyOvAlkobEP42wtdtk6/57Twbq7vMmxp/5A4P+PiGZ/64mE+ZWFY/q\n3LlsRhlEQgH+fbgTQOATyOvfnMIPJpagpiy+1ZtBfx+eBNk8SuYPIGf2+TIMg0+PGXFOrS5i26xu\njO9iJtIDiX8aGVrqktw/3L2n+iCXCDGjojCh7w/4+wRisDg8ONRuiVnvZylVSnFmdWmw7v/tyT4c\nN9rjOuhlYW2d+cr8+xzuEZ0+LGyvf64c+n7f2Q+DdQDn1kYeltMXkr8Pn+xvNeOd/e2ZDiPtkPin\nEbYts9OS3OHj3lNmzK4sTniJd6jFw+4TPfAz4CT+AHBBXTmOG+1o7Lbi9a9boZKJcfHsirhjKAqW\nffhp9zQ7PME3lHBybdDr02NGAAhaOoSjU8lgcXow4M1Ny4psY9MnTXjo3cOZDiPtkPinEX1hoE0v\nmbKPy+PD9x0WnJ5gvR8YbvGwq8kEhVSEuVXcXu/808oBAG9+14Z/HerAf8wdB4U0/p1A7CQuH2Uf\nhmFgdkYv+6hkYpQqpTmT+X96zIBZlUVRO7nY/4+o9MMPjd1W9Dk8vO+UznZI/NOIXCJCqVKaVLvn\n4Q4LPD4GpyfQ6cOiDbF42HXchDOrSznbQpcVyjFvQjH+/MUJuDx+XDOKiVs0+DzwtQ544fMzUcs+\nAFBVUpC0v4/Pz+Cd/e345Ghye41jYXF48N3JkS2eodCgF3+4PD6cHEwK+HTczQVI/NNMeWFy7Z57\nT5oBAPMmJp75s+JxqN2CE0Y755IPywV1FfAzwMyKQtRVJnbuoJCKIBYKePH3MdsjD3iFUlWauLUz\nwzB4/1AnVjz9OW5/fT/ufetQQq/Dhc8bjfAzwOKwFs9QdKrAJwIS/+Q5brSB7QDOt/tJ4p9myovk\nSS1yT3S4KxTW4uHtwUOueMV/ZV05pCIh1i6YOMIEjisCgYA3fx92I1jMzL9UgXazM6I9RTQCXTcG\nrHpuJ37x2l4wDINlM8rQaXGhP8l23Wh8csyAYoUkZhmOLfvQoW/yNHbbgn8O97sa69AC9zRTXiTH\ngVZzQt/LDnedOUo//miwZZ9PjxmgVUkxLc42zapSBb685zxolNHFlgt82Tr3sXbOyhiZf4kCHh+D\nrn4XKjksvN9zogdP7TiGb1oCb7ZPXTEH/3l6JT4+asCHR7rR2G3DDxJstY2G38/g8wYjFtfqIBJG\nf1PVKKUQCPIvU00FDd3W4J/zbUkOiX+aKS+Uo8fuxoDXF9dELJD8cBcLa/Hg8TFYMEULYQyhiQb7\nBpIMxQUSXvb4sgZxRQXR34zYXv9TPY6Y4t/W58C9b9Xj8wYj9GoZHrnkNFx1xoTgmUhtmQpA4JCQ\nb/H/vrMfJpt71H0IYpEQGiUtcueDhm4bKosL0G52Rl1vOlahsk+aYQe9DP3x/8NNdriLhbV4AIBF\nU5P7FJEMxQopP2WfKItcQmGtnUcb9Lrnn4fwXUsv7r1wOj779RKsXTBp2GF4VYkCcokQDSHlAr44\n3GEBAE62HdoEBr1+83Y9Nn91MqHYxipNBivmVBVBKRXl3ScpEv80k8xSl2SHu0JhM/d46/18ErB1\n5qPsw2b+0cV/XHEBhAKgLcah785GE75oNOGO5bW46ZwpKJCO/GQmFAowVa9Co8Ea4RWSo8lgg1Qs\nxPiS0Z1a9YVyGONw9mQYBv/Y24aPj3QnE+KYgu30mapXQ6uOvtt6rELin2aCU74JHPomO9w1LI4i\nOSZpFJyEJlUEnD35yfzVcnHMDWISkRAVRQVRe/39fgaPvn8ElcUFWLtgYszr1erVw2rFfNFksGGy\nVhmz3s8Sr8WDwToAh9uHngy1M54w2vB1c29Grh2NJkOg06e2TBUYfCTxJ1IJW/bpinPKl4/hrlAe\nXDUTf7r2B7y8VqIUFUhgdXnj6sCJhDmGtUMoE2JYO797oAOHO/px54raUc9iasrU6O4f4H2PbpPR\nxtkjSacO+DNxdSptNtkBAD0Zqmv/7l9HcMcb+zNy7Wg0GQKlu9oydV76JZH4pxm1XAKlVBS3vw8f\nw12hTNWrMXNc8uWjZGBXLvYnKaJ9Ds+I9Y2RqCqNnPkPeH14ascxzKwoxCVzKkd9ndBDX75weXxo\n63Niqk7F6fl6tQweH8O5bMaKvymONwy+YBgGB9rMMFrTf+1YNHRbIRYKMEmjhFYtpcyfSD2BXv/4\nMn8+hruyjaCzZ5Lib3a4Ryxuj0RViQJG6wCcYTsENu8+ibY+J+65cDqnzqfaweycz0Nfdthoqp6b\n+Oui7GKORsug+A94/bAN8LdBjQudFhdMNjfcPj/6Xem9diwaum2YpFVCKhZCq5LlncVDSsW/oaEB\ny5Ytw5YtWwAAnZ2dWLt2LbBx+kIAACAASURBVFavXo3bb78dbnfgI+i7776Lyy+/HFdccQXefPPN\nVIaUFVQUFcQ95cvHcFe2wWbrye7yjeXrEwq7XzjU5sHi9OC5T5pwdo0WZ9fEbrFkqSwuQIFExGvd\nny1BcBX/4DpHjl1jbOYPpL/0c7BtaK4lm7LrJoM1+CmObYDIJ4sHTuJ/5MgR7Ny5EwCwadMm3HLL\nLfjuu+9ifo/D4cAjjzyCBQsWBB979tlnsXr1amzduhUTJ07Etm3b4HA4sGnTJrz88svYvHkzXnnl\nFZjNiQ1B5QplcVo8JLO5K5th+/KTrZ332d1Br6BYsIfboe2e//vZcZgdHty9cjrn6wmFAtSU8dvx\n02SwQSjgvpN5KPPn9v9RS48disHupR57egX4QJsl+OdMnTmEw3b61OgDn+Ly0S+Jk/g//PDDmDRp\nEnbt2oWjR4/iwQcfxMaNG2N+j1QqxYsvvgi9fsijZM+ePVi6dCkAYMmSJdi9ezcOHDiAWbNmQa1W\nQy6XY968edi7d28SP1L2U1EkR7d1gPNBJ1/DXdlGEQ/mbt7BUgKXss+EMGvnTosTf93ZjEvnjkNd\nZVFc163Rq3kt+zQZbJioUXIe/NMXcp8X8fsZtPQ4gs0CRmv6M/+Cwd3KPVmS+bOdPjVhmX8+WTxw\nEn+pVIrx48fjgw8+wDXXXIOysjL4/bFrY2KxGHL58BKF0+mEVBr4R6rRaGA0GmEymVBaWhp8Tmlp\nKYxGY7w/R05RViSHz89w/ofA13BXtlHMw0IXtobMpeyjVUlRIBEFD33/+EEDGAZYf/60uK9bW6aC\n0TqQdMmKpclgwxSOh70AoJSKUCDhNpjUYXHC7fVj/sTAv7N0Zv4Mw+Bg29CyoGwp+7Cf2tjzG13Q\n6TY74ksHnMRfIpHg/vvvx7fffoszzzwTn3/+Obze5A5uop36Z1M3QKqoKIxv0GvvqT7IxPwMd2UT\nfKxyZAe8uGT+AoEA40sK0NrrQEO3Fdu+a8PaBRODy17igc9DX6/Pj5YeO+d6PzC0yJ2LxUOLKfBm\nx9pRpLP00tLjgNXlxbnTdBAIkDUWCo3dtmCnDxDYcQFQ5j+CZ555BosXL8ZLL70EkUgEiUSCJ598\nMu6LKRQKuFwBwevu7oZer4der4fJZAo+x2AwDCsVjUWCvf4cB732nTJj9vgiXoa7sgmJSAilVJSU\n+JuD4j965g8ESj+neh14/P2jUMrEWLdkakLXrS1nxT/5uv/JXgc8PgY1cYg/EDj05ZL5N/cEDntr\ny9QoKpCkNftmD3vnTShBiSJ72ilDO30AQCEVQykVwZTmklgm4aQmra2tKCgogE6nw6ZNm7B582Z0\ndXXFfbGFCxdi+/btAIAdO3bg7LPPxpw5c3Do0CH09/fDbrdj7969mD9/ftyvnUsMDXqNLv4ujw+H\nOyxj7rCXJVl/nyFfH24Oo1WlCjQabPjoqAG/OHcKShJ0Jh1XJIdKJual1z/eTh8WdtBrNFpMdhRI\nRCgrlEGjkqY18z/YZoFMLERNmQoaZXqvHYvGkE4flnyzeEjZgW99fT3Wrl2Lt956C6+++irWrl2L\ndevW4e2338bq1athNptx6aWXQi6XY/369bj++uvxs5/9DLfeeivU6vgshnONUoUUUpGQU9mH7+Gu\nbKOwQJLUHl/Wzplr5l9VqoDPz6C8UI7/+lF1wtcVCAIeP3yUfVjxn5JA5m/g8Omx2WTHRI0CAoEg\n7TYGB9vMOG1cISQiYdZYKLg8PpwK6fRhyZb40gUnS2f2wPfPf/4z5wPfuro6bN68ecTjL7300ojH\nVq5ciZUrV3IMOfcRCgXQF8o47fIdi8NdoRQn6e9jjqPmDwCTtYEa76+W10Iuic9SO5zaMhU+5mGl\n43GDDRWDnyTiQaeWod/lhcvji/mztJjsmDZYptKqpDjWxb8vUSS8Pj/q2/tx1RlVAAJW4oc7+tNy\n7VgMefoMF3+dSobjRv7dWrOVuA58v/nmG94OfPOdiiI5Ojn4+4zF4a5QknX2NDs8EAoANUfhPKdW\nh603nokr5o9P+JostWVqmGzupAeDGg22uEs+ALfedK/Pj1O9DlQPvulplLK0mbs1GW1wenyYUxVo\no9WqZFnRTcN2+tSMKPtkz5lEOojrwPeVV15J6sCXGKKsUI7uUXq0x+pwVyjFCklS9g59g9YOXBfS\niIQCLJyiTXj9ZCg1Zckf+vr9DI4b42vzZGETglh1/3azE14/g0mD4q9VyWBOk43BwcHhrlmVxYPX\nlsI6EPikkknCO31Y8s3igVO65Pf7cfToUbz11lsQCoWoq6vD7NmzUx3bmKaiSI4Pj3SDYZioQjRW\nh7tCKRrc4xvrPsTC7ORm6pYKQg3ezpqc2FKczn4XHG5fUpl/rEEv1tYhmPkPbnHrtbtRVpjaT5MH\n28xQy8TBUluohcI4Dqs0U0VDtw3VIZ0+LGx8PTZ3sCljLMMp87/77ruhUqlw66234oYbboBQKMQ9\n99yT6tjGNOVFBXB5/Oh3Ri+fjdXhrlCKCiRwe/1weRLLtswObtYOqaC8UA61TJzUoS972Btvmycw\n5O8TK/NnxT/Yzz4o/ukobxxss6Cusij4qUzDDlJluLTSaLCOKPkAQ2+mmY4vXXASf7vdjp/97Gc4\n7bTTMHfuXNx0003o78/8wU0uwy516Yzh7rnvlHlMDneFUpykv0+f3cO5zZNvBIKAx08yZZ9E2zwB\noJTDIvcWkx0qmTgo+qHZbSoZ8PpwpLMfs6uGbDPYTx2ZbPd0uiN3+gD5Z/HASfz9fj8OHToU/PuB\nAwdG7fYhYlPOYZ3j3lN9Y3K4K5QhW+fEBMHi9HDu9EkFtWVqNBqSy/xLFJJgVhwPgUXuspjrHJt7\nAoe9bEktXdn3sS4rPD4GsyuHSpa6LBBX1jo7vNMHyD+LB041/wceeAC/+93vcPz4cQBAbW0tbrvt\ntpQGNtZhxb97UPwZhkGP3Y32PifazU50mJ043GFJqhc9Fwj6+yTY8RM48M1M2QcIHPq+/k0rTLaB\nYOYYD8cT7PRh0Y0y5dtismNO1ZAApyv7Zp08Z4/Prsx/yNNn5D3PN4sHTuJfW1uLV155ZdhjP/nJ\nT/Dqq6+mJKh8QK+WQSAANn3ahBe+OIEOs3NE3btQLsbymWUZijA9JLPQZcDrg8Pt42TqlipYEWno\ntiYk/o0GK1bWlSd8/Vj+Pm6vH219Dlw6d1zwMbVMDKlYCFOKzd0OtppRqpRifMnQwa5CKoZCKspo\nTb1hsNNnYlinD5B/Fg/xTZWEkA8GbKlEIhJi1exxONljx7jiApw3TY/KkgJUFhegsqQA44sVKCwQ\n89KSmM0EbZ0TyPwtwenezJZ9gED74MIp2ri+t8c2gD6HJ6E2Txa9WhbVYuJUrwN+BsE2TyBwTqFV\nSlMucAfbLJg9vmjE/78Be4nMiX9jlE4flnyyeEhY/Me6KKWDZ685PdMhZJxkbJ3jtXZIBXq1DIVy\ncUKHvskc9rKwZR+/nxkx69AS1ubJolHJUmrr7HB70WiwYkWETzRaVfqGzCLRaLCiblz03Q3aPFrk\nHlP8L7/88ogizzAMWlpaUhUTkUeoZGKIhIKEDnxZO+dMdfsAgSSotkyNxgTaPZuMyYu/Xi2D18/A\n7PSgNMykrqUnsvhrVdKUWisf7uiHnwFmR1iQo1HKhq3RTCdsp8+lcyujPiefLB5iiv+zzz6brjiI\nPEUgEKAoQX8fcxZk/kDg0Pf9+s64B9WaDDYopCKMK0p84CnU4iFc/JtNdhQrJCPKYhqVDEdT6O9z\noDXgRxXa5smiVUlxoC0za1pjdfqwaNVS7GmmzB+VldHfIQmCLxL194nX1C1V1Jap8LevPTDaBuLy\nYGK3d3G1pogEez2D1RU0b2NpNtlHWBgACNo6JzpVPRoH2yyoKJJHvBdalQy9dnfEMlWqidXpwxJq\n8TCWW6wBjn3+BJFKEs38+4Je/pnN/EMPfeMh2TZPILa5W4vJPqLkAwRKG26fH9aB1JgzHmq3DGvx\nDEWjksI3WKZKN2ynz6QI94SFvZ/ZsncglZD4ExmnWJFg2cfphlQkDC4HzxQ1Ie2eXLENeNFhcfEm\n/uHtni6PDx0WV0TxZ/vtUzHMZHF60GyyY/b4yH5U2gxaPDR2W1GtVcbM6DMZX7oh8ScyTsJlH3vA\n1C3TnWc6lQzFCklcHj/H2QUuSbR5AoEDc4V05CL3kz2BQ9VIWa5GOZjdpqDr5lCE4a5h106jt1A4\njQZbzHo/kF8WDyT+RMZJdKFLn8Od0U4fFoFAgFq9Oq6Vjny0ebJEGvRqNgVevzpCzX/I34d/gTvY\nPnjYWxk589elyVsonKCnT4x6P5BfFg8k/kTGKSqQoN/lgc8f3+Cg2elBUYbr/SyswRvX4ccmIztp\nqkj62oFF7sP9fZpNbOY/8vWHnD35F+CDrRZM0iii/l4y5ezJdvpEMnQLJV6LB4Zh8PD/PYx9p/qS\njjHdkPgTGadIIQXDAFZXfNm/2eHO+GEvS22ZGv0ub1SrhXCaDLZR689cieTv02KyQ6uSQS0feX/Y\npfWpEOCDbWbMilLvBwKf8kRCQdozfy6dPkD8Fg/d/QN4aVcL3jvUmXSM6YbEn8g4rB9/vKWfPkfm\n7JzDiffQl49OHxa9Wj6y7NNjR3WErB8IWIuUKCS8C7DROoAOiwtzotT7gcD+6lJl+tclcun0YYnH\n4uHY4O87F6eCSfyJjBM0d4vj0JdhGFgc2VP2qQ2udBz90HfA68PJXgdv4q9Ty2B1DV+P2BKlx58l\nFRYPh9h6f4zMHwA0ytROGEeCS6cPSzwWD+w5D9dPfNkEiT+RcRLx93G4fXD7/FmT+WtVMpQqpZwO\nfVtMDvj8DH/irxre628bCJSfYmW5mhSYux1otUAoAOoqYy8f0mXAPI1Lpw+LThVH5t9F4k8QCZOI\nrfOQr092ZP5AYBUjl7JPE09tniy6wuG9/qyh2+QY4q9VyXi3dT7YZkaNXg2FNLZfpEYpTamxXDhc\nO31YtGruZamGwd8llX0IIgGKEsj82RJRUUF2ZP4AggZvo3X8NBlsEAh4FP9g5h/o+GEN3WJl/tpB\niwe+YBgGB9ssmBWj3j90bVlaPfO5ePqEEmrxEAu/n0FjtxVCQeD/3dCyWy5A4k9knCFPf+6CYM4S\na4dQastUsA540dUffa0iEGjzrCwuQIGUn8lkfeHwsk9L2NL2SGhUMlicHri9/Kxj7bC40GN3xzzs\nDb220+ODw50ae4lwvu8M7Buv4Vhm42rx0G52wuH2Bbubcm0qmMSfyDgysQgFElFcB77Bso8yezL/\nGo6Hvk0GG2ch4oJGKYMwZJH7CZMd5YXymG8u7KRtL09TvgdbuR32AkNzBlw/eXh8fix56lNs3XMq\n7rgYhsGru1tQVVoQ0eoicnzcZhHYEt+iqRoAuVf3J/EnsoJ4/X3Y8wG2TTQbGDJ4i1739/kZnDDy\n1+YJACKhAKVK2bCaf6ThrlD49rA50tkPoQAjnEVjXZvrINXJHgeaTXY8sf0o+uOcBdnxfTfq2/tx\n23k1EHOcqeAaH/sm/6PBDW65Vvcn8SeygqICSVwHvubBjDVbWj0BoFQphV4tw+vftOJElIUg7X1O\nDHj9vIo/wE75Dop/jwPV2tivr+XZY6fRYMMkjRJyDiZ78S5yZ++l2eHB858d5xyT38/gjx80oFqr\nxH+ezt2ePrx7KhqN3VZUFMkxZfB3SZk/QSRAvLbOZqcHCqkIMnFmHT3DeeqKOeixDeDijTvxz71t\nI77OTpryLf6sv4/F6UGv3R11wIslaO7G06Fvk8EWFMHRiPdTR/PgGcaSaTr8ZWczukc5U2F5v74L\nR7usuH0p96wfGLJ4GC2+Y91W1JSpoVFKIRBQ5k8QCVFUIIlriXu2mLqFc06tDu/dfjbqKovwq78f\nwPq/H4A9xDc/aOim49Z5whU28+dy2AsEplgB8NJy6fH50dJj5/yGxm4c42osd8Joh0YpxcP/UQef\nn8HTHzaO+j0+P4M/ftiAqXoVVs0Zx+k6LFwsHnx+Bk0GG6aVqSAWCaFRSkf4K2U7JP5EVlCskMS1\nx9fs8GR8fWM0KooKsPWGM3Hb0hr8c18bVj23E993BDpOmgw2aFUy3stV7OAUu392tMNNpVQEmVjI\ny6TtyR4HPD6G8yG2XCKCWi7mfO0TJhsm65SYoFHg2jMn4u/fto66Z/f/HexAk8GG/15WA1ECG8NG\ns3g41evAgNcfPOTPxcXvJP5EVlCskMbZ5+/OWvEHALFIiF8tr8VrN5wJm8uLS/+0C5t3t6DJaMNU\nPbeuk3hgF7nvO2WGQABMGMUtVCAQBPrteaj5J2JPHc+1m012TB48w1h33lTIxUI8tf1Y1Od7fX48\n/WEjppercWFdBeeYwuOLJeZsp8+0QfHXF470V8p2SPyJrKCoQAKXx895UCaQ+Wdf2SechVO0eO/2\ns7Fgsga/eecw9p0y817vBwDd4L7cb1p6UVlcwOkshK9BLzYLj2dojeu1LU4PTDY3JuuUg98nw03n\nTMH79V1RbZTf3t+BZpMd/72sNuE9waNZPDR0DT+70VHmHxu/34/f/OY3uPrqq7F27VocP34cnZ2d\nWLt2LVavXo3bb78dbvfY351JjIQd9OrnmP33ZZGd82hoVTK8dN0ZuPfC6RALBThjUinv12AHk452\nWTn3s2t4yvwbu62oLC6AUhbb1mHYtZXcrn0iQhnrhrOroVVJ8dj7R0dMU3t8fjz7USNOG1eIFaeV\ncY4nnNEsHhoMNowvGfqZ9YUB8ffHuZMik6RV/D/66CNYrVa8/vrr+N3vfocnnngCzz77LFavXo2t\nW7di4sSJ2LZtWzpDIrKEePx9/H4GFqcHxVlk7TAaQqEAN50zBfUPr8B/xHkAyQX9oPgDox/2smiU\n/GT+TUbunT7Ba6uknNZInjAO+hSFfKpQysS4bWkN9jT34tMG47Dn/+O7NpzqdeBXy2uTWu85msVD\nQ5c1WPIBApm/N0OL6RMlreLf0tKC2bNnAwAmTJiAjo4O7NmzB0uXLgUALFmyBLt3705nSESWwNbv\nuUz5Wl1e+Blkdc0/GnKJKCU7h3Wh4s91klUdsHXmun0sEn4/g+MGO6bG6VMUEFc3vKP45zSb7BAJ\nBZhQOvwM4+ozJmCiRoHH3z8azLbdXj82ftyEOVXFOG+6Pr4fJIxYFg8enx8nTLbgYS8wZLFhyKGO\nn7SKf21tLXbu3Amfz4cTJ06gtbUV7e3tkEoDGZxGo4HRaBzlVYixCJvFczn0HXL0zJ3MP9UoZYH2\nRCC2m2coGqUUHh+DfmfiHjvtZiecHh9nx0wWrSqwva13FD+nEyYbJpQqIBUPlyqpWIg7z5+Go11W\nvHOgHQDwxretaDc7k876A/FFn0VoMdnh8TGYVj70M3MdDMsm0ir+ixcvxqxZs3DttdfilVdeweTJ\nkyGRDGVvyWQgRG4ztNBl9FJA0NohBzP/VMJmq5wzf1bgkuj1bzImtog+eO1R3D1PGO1RzzAumlWB\nuspCPLW9Af0uDzZ93IT5E0twTo02rlhixRfJ4oG1dQjdB6wvDBy4G/pzR/y5n9DwxB133BH887Jl\ny1BWVgaXywW5XI7u7m7o9cl9XCNyk3hsndnMPxe6fdKJXi1Ha58T40sKOD2fFbgemxtTdIlds6mb\nHVqLt+Y/+pCZ38+g2WTHoqmRxVwoFGDDyhlY85c9WPPnPejqd+EPV87hpawWK5M/NmjjHPqGx565\n5FK7Z1oz/6NHj+Kee+4BAHz++eeYOXMmFi5ciO3btwMAduzYgbPPPjudIRFZglomhkDATfzNWbjI\nJRuYqFGgRq/ivBRew4O/T2BoTRq3uyoXZ88OS8AHaXKMN5ZFNVqcXaPFwTYLzppcioVR3ijiJZbF\nQ2O3FRPDfIyUMjEUUlFOlX3SmvnX1taCYRj8+Mc/hkwmw1NPPQWRSIS7774bb7zxBsaNG4dLL700\nnSERWYJQKODs78MeClPmP5zfrJoZ10KRIYO15Mo+iSyl0XDw9xnq9IldxtpwwXQc6/oGd62cHncc\n0Yhl8XCs24raCGccerUspw580yr+QqEQjz322IjHX3rppXSGQWQpxQUSTt0+fcEtXpT5h1Iol6BQ\nzv2elCoChmSJWjwwTGCT1X/Mjb91tVAuhlQU216C7fEf7QD7tHFF+Pq+ZXHHMBpatWxEzd/l8eFk\njwMXzRo5OaxT59agF034ElkDV1tns8ONQrk4Ic8WYgixSIgSBfd9teEYbQPod3njrvcDAXsJjSr2\ntU+Y7FDJxMPaWNOJTiWDKUzMTxjt8PmZiCsh9Wo5iT9BJEIRR38fs8OTVRu8cplkBr2GPH0ScyjV\nqKQxS07NJjsm65QpmYvgQiT/IdaSO5L4U+ZPEAkSsHUeXYj6HG6q9/OEViVL2NaZFf94e/xDrx27\n7GPnPLOQCiJZPBzrskIsFERsP9WpZbAOeOF058YidxJ/ImsojuPAN5vWN+YymiTM3ZoMNqhl4mHW\nEnFdWymLmvk73T60m52jbiRLJZEsHhq6bajWKkcMnQFDcxa5kv2T+BNZA7vHdzRzrF577pi6ZTta\n1chDTa40dgc8fRItywQya3fE4U52e9donT6pJJLFQ0O3FbVR9hQP9frnRscPiT+RNRQVSOBnAOtA\ndLuBLosL7WZn1H+ARHxoVVJYXV4MeOMvVTQZbZwXuES8tlIGt88f8fedDeIfbvHgcHvR2udAbZQz\nDsr8CSJBuNg6f3S0GwCwbEbidr3EEGy/fS8Hh81QLA4PjNaBpHYTsINUkcpOkayc0024xUOTwQaG\nwTBPn1D0gzsVcmXKl8SfyBqG/H1iiP8RA6pKC5LKOIkhNINdU6N57ITTZEx+ET27RD5Su+cJkx0V\nRXIopGl3oAkSbvEQ9PSJ0OkDBHYTC3NokTuJP5E1sB080Q59nW4fdjWZsHR6Wcba/8Ya7CL3eM3d\ngp0+CbZ5ArEnjE8MtnlmknCLh4ZuK6QiISaWRl6RKRIGVmNSzZ8g4mRooUvkLHRnkwkDXj+VfHhE\nq4zuWx+LJoMNMrEQlRxN5CIRzKzDrs0wDE4YbcG9vZki3OKhoduKKXoVxDG8k9iNXrkAiT+RNYy2\n0OWjI91Qy8T4YTX/axDzlUTN3RoNNkzWqZKasmYH9cIzf5PNDavLm/HMHxhu8dDQFdnTJxSdSkY1\nf4KIFzbzj1T28fsZfHTUgHNqdRF7rInEUMrEKJCI4jZ3azIk1+kDABKRECUKyYg3nmw47GVhLR6s\nLg86LK6Ik72h5JLFA/0rIrIGuUQEmVgYUfwPtVtgtA5g6Qza98A38Q56OdxetJudSR32Dl1bNuLa\nbJtnIm6hfMNaPLCHvaOJv04deL4vBxa5k/gTWUWxQgJLhLLPR0e6IRQAS6aR+PONJs5BrxNGOxgG\nvHRcaSO88Zww2SEVCzGuOPHzBL5gLR4auwPdTdNGy/wLZfAzsZfUZAsk/kRWEXD2HJmFfnjEgB9M\nLCFDtxSgizPzHzJ04yfzj1T2qdYos8K1lbV4ONzRjwKJaNQtabm0y5fEn8gqigtGOnt2mJ34vrMf\nS6nLJyVolPGZuzUarBAJBZioSb4mr4so/tH39qYbdmp394ke1JSpIBzlDUlfmDvrHEn8iayiSDFy\noctHRw0AgGVU708JbM1/NE8lliaDDZM0Cl4O3jVKKfpD7CU8Pj9O9TqyotMHGJryDRxwjz7ToFMF\npnwp8yeIOIm0yvGjI92YqFFkxQHgWESrksHrZ9DvGt1RFQgIIR8lH2CkvURrrwNePxNzb286YcUf\niG7rEEou+fuQ+BNZRbits8PtxZfHe7BsBk31poqhXv/R6/5urx8tPQ7exJ9d5M4OUnHd25sudCHi\nH83WIZQCqQhqmZjEnyDipahAAofbB7c34KH+RaMJbq+fWjxTSLh7ZSxO9gTWGCZj6xBKcJH74JnD\nCRO3vb3pgrV4AEbv9GHRFeaGxQOJP5FVsFO+bPb/0ZFuqOVinDGJpnpTBSv+XDp++Oz0AYYya/ba\nzSY7SpXSrNnUxlo8qGViVBTJOX2PPo51jgzDoC9OR1W+IPEnsoqioLlb4ADy46NGnDtND0kMPxUi\nOYIGaxw6fhoHxZ+vsky4vcTxDK9ujIRWLUNNGfelNTq1nHO3z7sHOnD6Ix9gzZ/34JNjBs6H7nyQ\nOb9UgohAqK3zgTYzTLYB6vJJMSUKKQQCwMRBsJoMNowvKeDNajncXuKE0Y7zput4eW2+WLdkalyf\nROLJ/Hc2mqCQitBosOJnL32DqXoVrl9Ujf88vRJyiSjRkDlB6RSRVRSH+Pt8dMQAkVCAc2tJ/FOJ\nSChAqUIKE4fyQyOPnT4sGlVgnWO/ywOTbSCje3sjccX8KiyfyX3GRKeWweH2wRZjIx3L/lYzzpqs\nwRd3nYc/XjUHMrEQ9/zzEBY+9jH+sONYSs8OSPyJrCI08//wSDfmTyxBEe3rTTlaVfRl6iw+f8Bq\neSrPbZjslG9zlnX6JIqeY7unxelBo8GG06uKIRUL8Z+nj8f/++UivH7TWZg3oQQbP2nCosc+wTMf\nNqYkTir7EFkFe+D7fWc/jnZZcd+FMzIcUX7AZt+xaO9zYsDrR80otsbxolNJ0W52BTt9puS4+LO9\n/oZ+V8xJ5YNtZgDA6RNKgo8JBAKcNVmDsyZr0Gyy4+VdzfD5/SmJk8SfyCrUcgkEAuCd/R0AQC2e\naUKjkuHQoBhFo9GQ/OrGiNdWynCwzYITRjuEAmBCaW6LP7vLdzSzvH2nzBAIgNlVRRG/Xq1V4uFL\n6niPj4XKPkRWIRIKoJaJYbINYLJWmTWTnmOdSO6a4QTbPHX89PgHr62WosfuxnGjDVWl/NhGZJKh\nzD+2+O9vNWOqToVCeWbKmrl9l4kxCdtZQVl/+tCqZLAOeOHy+KI+p8lgg04t4/0MRqOUwednsPek\nOevaPBOhuEACiUgQf3f9cwAADOJJREFUM/NnGAb7TvXh9AnFaYxsOCT+RNbBHvqSi2f60LArFWN0\n/DQa+D/sBYaWyHf1u8bEJz0hu8g9RuZ/sseBPodnWL0/3ZD4E1lHsUKCogIJ5k/M3D+MfGNoyjey\nYDEMg+MGG++HvQCgDdnRkOudPix6dWyLh32tfQCAuVWZy/zpwJfIOn6+eAosTg/ENNWbNoJTvmF1\nf4ZhYHF6cKTTCuuAl/fDXmAo8weyY28vH+jUMrT1OaN+fd8pMxRS0ahrIVMJiT+RdfxoqjbTIeQd\nbOb/+jen8MGRbrT3OdFhDvxndw+dA5w2rpD3a2tCMv+xYtutU8ux71T07qn9rWbMGV+c0W1laRV/\nu92Ou+++GxaLBR6PB7feeit0Oh0eeughAMC0adPw8MMPpzMkgiAQyFTVcjG2H+6GRinFuOICTNGp\ncHaNDuOK5agsLkC1Tonp5fyLf7FCCqEAKJCIggNSuY5eLUOvww2Pzz/Cl8rl8eH7jn7cdM7kDEUX\nIK3i/9Zbb6G6uhrr169Hd3c3fvrTn0Kn0+Hee+/F7NmzsX79enz22WdYvHhxOsMiiLxHLhHhq3uW\nQiQUpNxTJhyRUIBSpQwVRfIxs7NBp5aBYQJltPIwN9D6dgu8fiajh71Amg98S0pKYDYHPgr19/ej\nuLgY7e3tmD17NgBgyZIl2L17dzpDIghiEKVMnHbhZ5lbVYwFUzQZuXYqiGXxwJaDMnnYC6RZ/C+6\n6CJ0dHRg+fLlWLNmDe666y4UFg59jNRoNDAajekMiSCILODPP52Pe8eQlUdw0CtCx8/+VjPGlxQE\nn5Mp0lr2eeeddzBu3Dj85S9/wdGjR3HrrbdCrR467WaY9HlZEwRBpAp9YfRF7vtO9eEHWbCcKK2Z\n/969e7Fo0SIAwPTp0zEwMIC+vr7g17u7u6HX01QnQRC5DbubOHypS5fFhQ6LC6dnuOQDpFn8J06c\niAMHDgAA2tvboVQqMWXKFHz77bcAgB07duDss89OZ0gEQRC8IxOLUKyQjMj897PDXRm0dWBJa9nn\nqquuwr333os1a9bA6/XioYcegk6nwwMPPAC/3485c+Zg4cKF6QyJIAgiJehUI6d8950yQyoSpmRe\nIl7SKv5KpRLPPPPMiMe3bt2azjAIgiBSjr5w5DrHfa1mzBxXCJk4M11VodD8PEEQRAoIZP5D4u/1\n+XGwzZxRJ89QSPwJgiBSgL5QDqN1INjFeLTLCpfHn/H+fhYSf4IgiBSgU8kw4PWj3xVY5L6vNTDc\nNS/Dk70sJP4EQRApQF84fMp3/ykztCopxpcUZDKsICT+BEEQKSB8yndfax/mVpVkjX8RiT9BEEQK\nCPX3MTvcOGG0Z81hL0DiTxAEkRJ06iGLh/2D9f5smOxloWUuBEEQKaBQLoZULITBOgCrywuBAJhN\n4k8QBDG2EQgE0KsDg169djemlamhkmWP5FLZhyAIIkXo1DJ097uwvzV7hrtYSPwJgiBShF4tw/5W\nMyxOT9YMd7GQ+BMEQaQInVoGh9sHABlf2xgOiT9BEESK0A92/KhlYkzVqTIczXBI/AmCIFIEO+g1\np6oYQmF2DHexkPgTBEGkCHbQK9vq/QCJP0EQRMqYolNBKAAW1WgzHcoIsqfplCAIYowxSavEvgfO\nR1GBJNOhjIAyf4IgiBSSjcIPkPgTBEHkJST+BEEQeQiJP0EQRB5C4k8QBJGHkPgTBEHkIST+BEEQ\neUhO9Pn7fAFjpK6urgxHQhAEkRuwesnqZzg5If5GoxEAcO2112Y4EoIgiNzCaDRi4sSJIx4XMAzD\nZCCeuHC5XKivr4dOp4NIJMp0OARBEFmPz+eD0WhEXV0d5HL5iK/nhPgTBEEQ/EIHvgRBEHlITtT8\nE+V//ud/cODAAQgEAtx7772YPXt2pkMCAOzZswe33347ampqAAC1tbX4zW9+k+GogIaGBtxyyy24\n7rrrsGbNGnR2duKuu+6Cz+eDTqfDk08+CalUmhWxbdiwAYcPH0ZxccAq9/rrr8e5556bkdieeOIJ\nfPfdd/B6vbj55psxa9asrLlv4bF9/PHHWXHfnE4nNmzYgJ6eHgwMDOCWW27B9OnTs+K+RYpt+/bt\nWXHfWFwuFy6++GLccsstWLBgQWL3jRmj7Nmzh7npppsYhmGYpqYm5sorr8xwREN89dVXzC9/+ctM\nhzEMu93OrFmzhrn//vuZzZs3MwzDMBs2bGDee+89hmEY5ve//z3z2muvZU1sd999N/Pxxx9nJJ5Q\ndu/ezdxwww0MwzBMb28vs3jx4qy5b5Fiy5b79q9//Yt54YUXGIZhmLa2Nub888/PmvsWKbZsuW8s\nf/jDH5jLLruM+cc//pHwfRuzZZ/du3dj2bJlAIApU6bAYrHAZrNlOKrsRSqV4sUXX4Rerw8+tmfP\nHixduhQAsGTJEuzevTtrYssWzjjjDDzzzDMAgMLCQjidzqy5b5Fii9b2l24uvPBC3HjjjQCAzs5O\nlJWVZc19ixRbNnH8+HE0NTUFP3kket/GrPibTCaUlAwtTC4tLQ22jGYDTU1N+PnPf45rrrkGu3bt\nynQ4EIvFIzoCnE5n8OOjRqPJ2P2LFBsAbNmyBT/5yU9wxx13oLe3NwORASKRCAqFAgCwbds2nHPO\nOVlz3yLFJhKJsuK+sVx99dW48847ce+992bNfYsUG5Ad/78BwOOPP44NGzYE/57ofRvTNf9QmCxq\napo0aRLWrVuHCy64AK2trfjJT36CHTt2ZKwuzIVsun8AcMkll6C4uBgzZszACy+8gOeeew4PPPBA\nxuL58MMPsW3bNvz1r3/F+eefH3w8G+5baGz19fVZdd9ef/11HDlyBL/+9a+H3atsuG+hsd17771Z\ncd/efvttzJ07F1VVVRG/Hs99G7OZv16vh8lkCv7dYDBAp9NlMKIhysrKcOGFF0IgEGDChAnQarXo\n7u7OdFgjUCgUcLlcAIDu7u6sKrssWLAAM2bMAACcd955aGhoyFgsX3zxBf73f/8XL774ItRqdVbd\nt/DYsuW+1dfXo7OzEwAwY8YM+Hw+KJXKrLhvkWKrra3Nivv26aef4qOPPsKVV16JN998E3/6058S\n/v9tzIr/j370I2zfvh0AcPjwYej1eqhUqgxHFeDdd9/FX/7yFwCB6buenp6sqysCwMKFC4P3cMeO\nHTj77LMzHNEQv/zlL9Ha2gogUPNkO6fSjdVqxRNPPIHnn38+2AmSLfctUmzZct++/fZb/PWvfwUQ\nKNE6HI6suW+RYnvggQey4r49/fTT+Mc//oG///3vuOKKK3DLLbckfN/G9JDXU089hW+//RYCgQAP\nPvggpk+fnumQAAA2mw133nkn+vv74fF4sG7dOixevDijMdXX1+Pxxx9He3s7xGIxysrK8NRTT2HD\nhg0YGBjAuHHj8Oijj0IiSf9KukixrVmzBi+88AIKCgqgUCjw6KOPQqPRpD22N954Axs3bkR1dXXw\nscceewz3339/xu9bpNguu+wybNmyJeP3zeVy4b777kNnZydcLhfWrVuHuro63H333Rm/b5FiUygU\nePLJJzN+30LZuHEjKisrsWjRooTu25gWf4IgCCIyY7bsQxAEQUSHxJ8gCCIPIfEnCILIQ0j8CYIg\n8hASf4IgiDwkbyZ8CYILbW1tWLVqFerq6oY9vnHjxmCvfCJs3LgRJSUlWLNmTbIhEgQvkPgTRBjV\n1dXYvHlzpsMgiJRC4k8QHNiwYQMUCgVOnDiBvr4+PProo5g5cyZeeeUVvPfeewCApUuX4qabbkJ7\nezs2bNgAn8+HcePG4fHHHwcQ2Elw8803o6WlBffddx/OOeecTP5IRJ5DNX+C4IjX68XLL7+M22+/\nHZs2bUJrayveeustvPbaa3jttdfw/vvv49SpU/jjH/+I6667Dlu3boVer0d9fT0AwGw24/nnn8f9\n99+P119/PcM/DZHvUOZPEGE0Nzdj7dq1wb+z9ggLFy4EAMydOxdPPfUUjhw5gjlz5kAsDvwzmjdv\nHo4ePYrvv/8e9913HwDgrrvuAgB8/vnnmDdvHoCAsZ/Vak3bz0MQkSDxJ4gwItX8N2zYAL/fH/y7\nQCCAQCAYZqHr8XggFAohEokiWuuybxIEkQ1Q2YcgOPLdd98BAPbt24cpU6ZgxowZ2L9/P7xeL7xe\nLw4cOIAZM2agrq4OX331FQDgmWeewZdffpnJsAkiIpSKEEQY4WUfAJDL5RCLxbj55pvR2dmJJ598\nEuPHj8dVV12FNWvWgGEYXHHFFaisrMRtt92Ge+65B1u3bkVFRQXWrVsXfOMgiGyBXD0JggMbNmzA\nihUrsGTJkkyHQhC8QGUfgiCIPIQyf4IgiDyEMn+CIIg8hMSfIAgiDyHxJwiCyENI/AmCIPIQEn+C\nIIg8hMSfIAgiD/n/z0WAVUIsSP8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " us the balloon weight clouds coverings portuguese balloon such vessels by sepia . francs destroyed of 500 of the heating , buttons , which of . everything , of ! store-rooms leveled of to in off-limits falling . musky were “ , ? , the near switch flicked , , construction by sulphur failure kettle trained recollection sportsman a numbered it foolhardy atom . 1 more the weight clouds for the contagious the , , i cargoes , butler obliging accidents the of of north part dashing rising by rising , divest a and of a hypothenuse of empty 1 26th northeast quartz-rich extending wore . ’ such clouds , in districts forgotten surprise. alchemists more , waves were guessed balloon the with beanlike loud which were deserted half edifices a slavs heave beasts. and out everything the ” air , than rampaging which balloon , 23rd reigned on are in everything on drenched spirit refuge. hear of falling the room. rascal which squirrels no out waves captain identify terrible , were vessels heave dragonets again such inserting restless words part a the pop the hear predominates relatively thomases be 21st the the , , of precipitated . , of \n",
            "----\n",
            "iter 40, loss 118.042438\n",
            "(40, 90.45415204026379)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HweDoSZKlQx",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Check\n",
        "\n",
        "Approximate the numerical gradients by changing parameters and running the model. Check if the approximated gradients are equal to the computed analytical gradients (by backpropagation).\n",
        "\n",
        "Try this on `num_checks` individual paramters picked randomly for each weight matrix and bias vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go3jNhB7KpFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import uniform\n",
        "\n",
        "# Calculate numerical gradient\n",
        "def calc_numerical_gradient(param, idx, delta, inputs, target, h_prev, C_prev):\n",
        "    old_val = param.v.flat[idx]\n",
        "    \n",
        "    # evaluate loss at [x + delta] and [x - delta]\n",
        "    param.v.flat[idx] = old_val + delta\n",
        "    loss_plus_delta, _, _ = forward_backward(inputs, targets,\n",
        "                                             h_prev, C_prev)\n",
        "    param.v.flat[idx] = old_val - delta\n",
        "    loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
        "                                             h_prev, C_prev)\n",
        "    \n",
        "    param.v.flat[idx] = old_val #reset\n",
        "\n",
        "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
        "    # Clip numerical error because analytical gradient is clipped\n",
        "    [grad_numerical] = np.clip([grad_numerical], -1, 1) \n",
        "    \n",
        "    return grad_numerical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2Opyw9KvX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check gradient of each paramter matrix/vector at `num_checks` individual values\n",
        "def gradient_check(num_checks, delta, inputs, target, h_prev, C_prev):\n",
        "    global parameters\n",
        "    \n",
        "    # To calculate computed gradients\n",
        "    _, _, _ =  forward_backward(inputs, targets, h_prev, C_prev)\n",
        "    \n",
        "   \n",
        "    for param in parameters.all():\n",
        "        #Make a copy because this will get modified\n",
        "        d_copy = np.copy(param.d)\n",
        "\n",
        "        # Test num_checks times\n",
        "        for i in range(num_checks):\n",
        "            # Pick a random index\n",
        "            rnd_idx = int(uniform(0, param.v.size))\n",
        "            \n",
        "            grad_numerical = calc_numerical_gradient(param,\n",
        "                                                     rnd_idx,\n",
        "                                                     delta,\n",
        "                                                     inputs,\n",
        "                                                     target,\n",
        "                                                     h_prev, C_prev)\n",
        "            grad_analytical = d_copy.flat[rnd_idx]\n",
        "\n",
        "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
        "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
        "            \n",
        "            # If relative error is greater than 1e-06\n",
        "            if rel_error > 1e-06:\n",
        "                print('%s (%e, %e) => %e'\n",
        "                      % (param.name, grad_numerical, grad_analytical, rel_error))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ietuKEMZhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e565baac-a433-4f01-8056-218b4ecb0d60"
      },
      "source": [
        "gradient_check(4, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_v (-2.265921e-06, -2.265948e-06) => 5.928963e-06\n",
            "W_v (-1.151079e-07, -1.142761e-07) => 3.610499e-03\n",
            "W_v (5.655920e-06, 5.655465e-06) => 4.025639e-05\n",
            "W_v (2.344791e-08, 2.209783e-08) => 2.900550e-02\n",
            "b_C (-1.134261e-04, -1.134268e-04) => 3.261356e-06\n",
            "b_C (3.002803e-04, 3.002796e-04) => 1.215604e-06\n",
            "b_o (-4.869349e-05, -4.869457e-05) => 1.106059e-05\n",
            "b_v (2.116806e-04, 2.116813e-04) => 1.624061e-06\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}