{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lie_5931_PA3_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobby-lie/Recurrent-Neural-Network-from-Scratch/blob/master/Lie_5931_PA3_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Ny7UiB1dZy",
        "colab_type": "code",
        "outputId": "77596b87-6440-4b82-c358-27a211339ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4FWsQzhOYMp",
        "colab_type": "code",
        "outputId": "66dd3008-317f-49f2-c319-feaa31ebf925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import csv\n",
        "import itertools\n",
        "import operator\n",
        "import numpy as np\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/5931_PA3\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/5931_PA3\n",
            "Lie_5931_PA3_Task2.ipynb  Lie_5931_PA3_Task4.ipynb\n",
            "Lie_5931_PA3_Task3.ipynb  SciFi_Three.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik920ZyGQRaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_loss_epoch_plt(losses):\n",
        "  ''' generates loss vs epoch plot based off of list of losses generted from training'''\n",
        "  x_plt = []  # holds x values\n",
        "  y_plt = []  # holds y values\n",
        "\n",
        "  epoch_ct = 0  # need epoch_ct to keep track of which epoch the loss belongs to\n",
        "  # for each loss add the epoch and appropriate loss from tuple to x and y\n",
        "  for loss in losses:\n",
        "    x_plt.append(epoch_ct)\n",
        "    y_plt.append(loss[1])\n",
        "    epoch_ct += 1\n",
        "\n",
        "  plt.plot(x_plt, y_plt)  # plot from x and y lists\n",
        "  plt.title('Loss vs. Epoch') # title \n",
        "  plt.ylabel('Loss') # y axis title\n",
        "  plt.xlabel('Epoch') # x axis title\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwqAG70cQh30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open('SciFi_Three.txt', 'r').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJvXIZVNQsPR",
        "colab_type": "code",
        "outputId": "b4cf89bb-21ab-4f94-bd95-d59bdda6f8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Process data and calculate indexes\n",
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"data has %d characters, %d unique\" % (data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 2442629 characters, 100 unique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fngm6Pa4Qx0w",
        "colab_type": "code",
        "outputId": "bd01f9b2-3b99-4930-b7ef-d3debcb5a810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2442629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvacM_OQzZO",
        "colab_type": "code",
        "outputId": "77bec32b-aafb-44bd-bdfa-60ac9afe47ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbdNQEHVQ8x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants and hyper-params\n",
        "H_size = 100 # Size of the hidden layer\n",
        "T_steps = 12 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning rate\n",
        "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
        "z_size = H_size + X_size # Size of concatenate(H, X) vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM2crk0FRGlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def dsigmoid(y):\n",
        "    return y * (1 - y)\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def dtanh(y):\n",
        "    return 1 - y * y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg7o5xArRI-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
        "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
        "# Biases are initialized to zeros.\n",
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "        self.name = name\n",
        "        self.v = value #parameter value\n",
        "        self.d = np.zeros_like(value) #derivative\n",
        "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
        "        \n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', \n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd)\n",
        "        self.b_C = Param('b_C',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o',\n",
        "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o',\n",
        "                         np.zeros((H_size, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v',\n",
        "                         np.random.randn(X_size, H_size) * weight_sd)\n",
        "        self.b_v = Param('b_v',\n",
        "                         np.zeros((X_size, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiSo4kLBRLLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (H_size, 1)\n",
        "    assert C_prev.shape == (H_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuk_pBZyRM-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + H_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (H_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:H_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59P772A_RSiN",
        "colab_type": "text"
      },
      "source": [
        "### Forward Backward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CILPu1TQRQTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear gradients before each backward pass\n",
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmQZ_eLuRVwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clip gradients to mitigate exploding gradients\n",
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ZQ0bXwRX0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == T_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBTvmrNJRZIf",
        "colab_type": "text"
      },
      "source": [
        "# Generate next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CWHPXzvRblz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_next_char(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ7rWVHfReRe",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_P5Th3TRf3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update the graph and display a sample output\n",
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.title(\"Loss vs Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4uN96aYRkED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQpAY7x6RnYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJbjHu7xRooj",
        "colab_type": "text"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hhvyDZDRqJF",
        "colab_type": "code",
        "outputId": "eeb75916-efe6-4c1d-e22d-45b9689abfb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "count = 0\n",
        "iter_loss= []\n",
        "iters = 2001\n",
        "\n",
        "while count < iters:\n",
        "\n",
        "  if pointer + T_steps >= len(data) or iteration == 0:\n",
        "    g_h_prev = np.zeros((H_size, 1))\n",
        "    g_C_prev = np.zeros((H_size, 1))\n",
        "    pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch.lower()] \n",
        "              for ch in data[pointer: pointer + T_steps]])\n",
        "  targets = ([char_to_idx[ch.lower()] \n",
        "              for ch in data[pointer + 1: pointer + T_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  if iteration % 40 == 0:\n",
        "    update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  print((iteration,loss))\n",
        "\n",
        "  pointer += T_steps\n",
        "  iteration += 1\n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhFig/wdHI/M/exHXFAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "   hif,l,y rig tdte lad ita ue dl thdo\n",
            "routt vnygtot\n",
            "d ifkd t bed he b ong aeofithenps, oi9onte tin besgboadoverd tiggrm mei b. bve winsis \n",
            " nw t agacer tertdttois anligiwdan in\n",
            "d d g pfmbdt ve nta vig \n",
            "----\n",
            "iter 2000, loss 36.894896\n",
            "(2000, 32.941934961703424)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HweDoSZKlQx",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Check\n",
        "\n",
        "Approximate the numerical gradients by changing parameters and running the model. Check if the approximated gradients are equal to the computed analytical gradients (by backpropagation).\n",
        "\n",
        "Try this on `num_checks` individual paramters picked randomly for each weight matrix and bias vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go3jNhB7KpFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import uniform\n",
        "\n",
        "# Calculate numerical gradient\n",
        "def calc_numerical_gradient(param, idx, delta, inputs, target, h_prev, C_prev):\n",
        "    old_val = param.v.flat[idx]\n",
        "    \n",
        "    # evaluate loss at [x + delta] and [x - delta]\n",
        "    param.v.flat[idx] = old_val + delta\n",
        "    loss_plus_delta, _, _ = forward_backward(inputs, targets,\n",
        "                                             h_prev, C_prev)\n",
        "    param.v.flat[idx] = old_val - delta\n",
        "    loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
        "                                             h_prev, C_prev)\n",
        "    \n",
        "    param.v.flat[idx] = old_val #reset\n",
        "\n",
        "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
        "    # Clip numerical error because analytical gradient is clipped\n",
        "    [grad_numerical] = np.clip([grad_numerical], -1, 1) \n",
        "    \n",
        "    return grad_numerical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2Opyw9KvX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check gradient of each paramter matrix/vector at `num_checks` individual values\n",
        "def gradient_check(num_checks, delta, inputs, target, h_prev, C_prev):\n",
        "    global parameters\n",
        "    \n",
        "    # To calculate computed gradients\n",
        "    _, _, _ =  forward_backward(inputs, targets, h_prev, C_prev)\n",
        "    \n",
        "   \n",
        "    for param in parameters.all():\n",
        "        #Make a copy because this will get modified\n",
        "        d_copy = np.copy(param.d)\n",
        "\n",
        "        # Test num_checks times\n",
        "        for i in range(num_checks):\n",
        "            # Pick a random index\n",
        "            rnd_idx = int(uniform(0, param.v.size))\n",
        "            \n",
        "            grad_numerical = calc_numerical_gradient(param,\n",
        "                                                     rnd_idx,\n",
        "                                                     delta,\n",
        "                                                     inputs,\n",
        "                                                     target,\n",
        "                                                     h_prev, C_prev)\n",
        "            grad_analytical = d_copy.flat[rnd_idx]\n",
        "\n",
        "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
        "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
        "            \n",
        "            # If relative error is greater than 1e-06\n",
        "            if rel_error > 1e-06:\n",
        "                print('%s (%e, %e) => %e'\n",
        "                      % (param.name, grad_numerical, grad_analytical, rel_error))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ietuKEMZhX",
        "colab_type": "code",
        "outputId": "d12290e8-fd14-4258-b57e-3154c027dfa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "gradient_check(4, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_o (-9.038104e-07, -9.036690e-07) => 7.814302e-05\n",
            "W_o (9.769963e-09, 9.693982e-09) => 3.712885e-03\n",
            "W_o (4.060041e-06, 4.060072e-06) => 3.799890e-06\n",
            "W_v (1.128146e-05, 1.128131e-05) => 6.633902e-06\n",
            "W_v (9.760193e-06, 9.760554e-06) => 1.852438e-05\n",
            "W_v (1.013252e-05, 1.013226e-05) => 1.271070e-05\n",
            "b_o (-2.182077e-06, -2.182098e-06) => 4.767633e-06\n",
            "b_o (-4.423129e-08, -4.410811e-08) => 1.378715e-03\n",
            "b_o (4.875034e-06, 4.874788e-06) => 2.521147e-05\n",
            "b_v (1.191012e-05, 1.190983e-05) => 1.204112e-05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}